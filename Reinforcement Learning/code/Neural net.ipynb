{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s39SnnxrZxsx"
   },
   "source": [
    "# Chapter 6. Neural net for Classification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1. Deep learning frameworks : \n",
    "- a library for deep learning which supports\n",
    "    - __Tensor__ : n-dim array (of numpy) + $\\alpha$\n",
    "        * basic unit of data flow in computation graph\n",
    "    - __Computation graph__ of tensors\n",
    "        * graph representing __flow of tensors__ (from input to output to loss)\n",
    "        * __augo-gradient__ is provided\n",
    "            * optimization using __gradient descent__\n",
    "            * it is called __back-propagation__\n",
    "                - __gradient__ information __flows backward__ in computation graph \n",
    "                - from loss to output to input\n",
    "    - Computation can utilize __GPU__ very easily\n",
    "        * with minimal effort of model developer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.Pytorch.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.Installing Pytorch.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.Tensor.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.Tensor2.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.Tensor3.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &nbsp;\n",
    "## &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2. Neural Net\n",
    "\n",
    "<img src=\"figures/Ch6.Neural net.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.SLP.png\" width=600>\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# &nbsp;\n",
    "### Training NN for only one data $(x,y)$\n",
    "<img src=\"figures/Ch6.Training NN.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training NN for training data set $\\{(x^{(i)},y^{(i)}); i\\in D_{train}\\}$\n",
    "- loss function = objective function to minimize\n",
    "- gradient descent method\n",
    "<img src=\"figures/Ch6.Training NN Loss.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy, Cross-entropy, KL divergence : Information theory by Shannon \n",
    "- consider a probabilty distribution $\\mathbf{p} = (p_1, ..., p_K)$ \n",
    "- __entropy__ $H(\\mathbf{p}) = -\\sum_{x=1}^K p_x\\log p_x$\n",
    "    - $H(\\mathbf{p})$ : amount of information, level of randomness\n",
    "    - $H(\\mathbf{p})$ attains maximum when $\\mathbf{p}$ is [____________]\n",
    "        * $p_x = \\frac{1}{K} \\to H(\\mathbf{p}) = \\log K$\n",
    "    - $H(\\mathbf{p})=0$ (minimum), when $p_c = 1$ and $p_x = 0$ for all other $x$\n",
    "- __cross-entrpy__ $H(\\mathbf{p}, \\mathbf{q}) = -\\sum_{x=1}^K p_x\\log q_x$\n",
    "    - $\\mathbf{q} = (q_1, ..., q_K)$ : another distribution\n",
    "    - $H(\\mathbf{p}, \\mathbf{q})$ attains minimum when $\\mathbf{p} = \\mathbf{q}$\n",
    "- __KL (Kullback-Leibler) divergence__  $KL(\\mathbf{p}, \\mathbf{q}) = D_{KL}(\\mathbf{p} || \\mathbf{q})$\n",
    "    - $KL(\\mathbf{p}, \\mathbf{q}) = -\\sum_{x=1}^K p_x\\log \\frac{q_x}{p_x}$\n",
    "    - $KL(\\mathbf{p}, \\mathbf{q}) = -\\sum_{x=1}^K p_x\\log q_x + \\sum_{x=1}^K p_x\\log p_x = H(\\mathbf{p}, \\mathbf{q}) - H(\\mathbf{p})$\n",
    "    - $KL(\\mathbf{p}, \\mathbf{q}) \\ne KL(\\mathbf{q}, \\mathbf{p})$\n",
    "- Entropy is also defined for continuous distribution pdf $p(x)$\n",
    "    - $H(\\mathbf{p}) = -\\int_D p(x)\\log p(x) dx$\n",
    "    - $H(\\mathbf{p}, \\mathbf{q}) = -\\int_D p(x)\\log q(x) dx$\n",
    "    - $KL(\\mathbf{p}, \\mathbf{q}) = -\\int_D p(x)\\frac{q(x)}{p(x)} dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3. Training NN by back-propagation\n",
    "- how to compute gradient : auto-gradient (back-propagation thru computation graph)\n",
    "\n",
    "<img src=\"figures/Ch6.Training NN Opt.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.Backprop.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-4. NN for classigying MNIST data \n",
    "### SLP (Single Layer Perceptron) \n",
    "<img src=\"figures/Ch6.SLP for MNIST.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4-1. class NN_classifier\n",
    "* __members__\n",
    "    * n_class : # of classes\n",
    "    * __nn_model__ : neural net model\n",
    "    * opt : optimizer\n",
    "    * train_loader : training data loader\n",
    "    * test_loader : test data loader\n",
    "* __methods__\n",
    "    * __prepare_data__() : prepare training data and test data\n",
    "    * fit_epoch() : fit nn_model using 1-epoch of training data\n",
    "    * __fit__() : fit nn_model for several epochs of training data\n",
    "    * accuracy() : compute accuracy score\n",
    "    * test() : evaluate accuracy for test data\n",
    "    * __score__() : compute accuracy score \n",
    "    * predict_proba() : compute class probability\n",
    "    * __predict__() : predict class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_classifier:\n",
    "    def __init__(self, nn_model, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.set_nn_model(nn_model)\n",
    "\n",
    "    def set_nn_model (self, nn_model):\n",
    "        self.nn_model = nn_model\n",
    "        self.nn_model.to(self.device)\n",
    "        self.prepare_optimizer()\n",
    "\n",
    "    def prepare_optimizer(self, lr=0.001, wd=0.001):\n",
    "        p = self.nn_model.parameters()\n",
    "        # self.opt = torch.optim.SGD(p, lr=lr, momentum=0.9, weight_decay=wd)\n",
    "        self.opt = torch.optim.Adam(p, lr=lr, weight_decay=wd)\n",
    "        return self.opt                    \n",
    "                     \n",
    "    def prepare_data(self, data_class, batch_size=128):\n",
    "        # trans : pipeline 1) convert to Tensor, 2) normalize to standard normal \n",
    "        if data_class == datasets.MNIST:\n",
    "            mean = 0.1307\n",
    "            std = 0.3081\n",
    "        else:\n",
    "            mean = (0.5, 0.5, 0.5)\n",
    "            std = (0.5, 0.5, 0.5)\n",
    "        trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        train_set = data_class(root='data', train=True, transform=trans, download=True)\n",
    "        test_set = data_class(root='data', train=False, transform=trans, download=True)\n",
    "        self.train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "        self.test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "    def fit_epoch(self):\n",
    "        self.nn_model.train()\n",
    "        total_step = len(self.train_loader)\n",
    "        incorrect = 0\n",
    "        for i, (X, Y) in enumerate(self.train_loader):\n",
    "            X = X.to(self.device)\n",
    "            Y = Y.to(self.device)\n",
    "            m = len(Y)\n",
    "\n",
    "            # Forward pass\n",
    "            out = self.nn_model(X)  # same as model.forward(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(out, Y)\n",
    "\n",
    "            # Backprop\n",
    "            self.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "\n",
    "            # Track the accuracy\n",
    "            score = self.accuracy(out, Y)\n",
    "            self.score_list.append(score)\n",
    "            if (i+1) % 100 == 0 or (i+1)==total_step:\n",
    "                print(f'Step [{i+1}/{total_step}], Loss: {loss.item():.4f}, Train acc.: {score*100:.2f}%')\n",
    "\n",
    "    def fit(self, n_epochs=10):\n",
    "        self.score_list = []\n",
    "        for epoch in range(n_epochs):\n",
    "            print (\"Epoch %d / %d\"%(epoch+1, n_epochs))\n",
    "            self.fit_epoch()\n",
    "        self.test()\n",
    "        plt.plot(self.score_list)\n",
    "        \n",
    "    def accuracy(self, logit, Y, cm=None):\n",
    "        total = Y.size(0)\n",
    "        _, Y_hat = torch.max(logit.data, axis=1)\n",
    "        correct = (Y_hat == Y).sum().item()\n",
    "        acc = correct / total\n",
    "        if cm is not None: # update confusion matrix\n",
    "            for i in range(total):\n",
    "                c = Y[i]\n",
    "                p = Y_hat[i]\n",
    "                cm[c][p] += 1\n",
    "        return acc\n",
    "\n",
    "    def score(self, X, Y, cm=None):\n",
    "        self.nn_model.eval()\n",
    "        X = X.to(self.device)\n",
    "        Y = Y.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            logit = self.nn_model(X)\n",
    "        acc = self.accuracy(logit, Y, cm)        \n",
    "        return acc\n",
    "        \n",
    "    def test(self):\n",
    "        self.nn_model.eval()\n",
    "        n = self.n_class\n",
    "        cm = np.zeros((n,n), dtype=\"i\")\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X, Y in self.test_loader:\n",
    "            acc = self.score(X, Y, cm)\n",
    "            n = Y.size(0)\n",
    "            correct += n*acc\n",
    "            total += n\n",
    "        print(f'Test accuracy of the model: {correct/total*100:.2f}%')\n",
    "        print (cm)        \n",
    "    \n",
    "    def predict_logit(self, X):\n",
    "        self.nn_model.eval()\n",
    "        X = X.to(self.device)\n",
    "        logit = self.nn_model(X)\n",
    "        return logit\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        logit = self.predict_logit(X)\n",
    "        p_hat = F.softmax(logit, dim=1)\n",
    "        return p_hat   \n",
    "\n",
    "    def predict(self, X):\n",
    "        logit = self.predict_logit(X)\n",
    "        _, Y_hat = torch.max(logit.data, axis=1)\n",
    "        return Y_hat\n",
    "\n",
    "\n",
    "    def adv_example(self, x, y, eps=0.01):\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        x.requires_grad_()\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            # Forward pass\n",
    "            out = self.nn_model(x)  # same as model.forward(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(out, y)\n",
    "\n",
    "        grad = torch.autograd.grad(loss, [x])[0]\n",
    "        grad = eps * grad.detach()\n",
    "        xp = x.detach() + grad  # adv. example\n",
    "        # sgn_grad = torch.sign(grad)\n",
    "        # xp = x.detach() + sgn_grad  # adv. example\n",
    "        return xp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &nbsp;\n",
    "### 6-4-2. class SLP\n",
    "<img src=\"figures/Ch6.Class SLP.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* methds\n",
    "    * __init__(D_in, D_out) : to prepare layers, which contains parameters ($\\mathbf(w)$)\n",
    "    * __forward__(x) : compute forward pass of neural net for input x\n",
    "        * actual computation graph is built here $\\to$ _dynamic computation graph_\n",
    "            * layers defined in __init__() method are connected here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(D_in, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        y = self.fc(x)\n",
    "        return y  # softmax is done within F.cross_entropy\n",
    "        # return F.softmax(y, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.SLP accuracy.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "Step [100/469], Loss: 0.4740, Train acc.: 85.16%\n",
      "Step [200/469], Loss: 0.3273, Train acc.: 89.84%\n",
      "Step [300/469], Loss: 0.2887, Train acc.: 91.41%\n",
      "Step [400/469], Loss: 0.2461, Train acc.: 93.75%\n",
      "Step [469/469], Loss: 0.2785, Train acc.: 89.58%\n",
      "Epoch 2 / 10\n",
      "Step [100/469], Loss: 0.3297, Train acc.: 89.84%\n",
      "Step [200/469], Loss: 0.3225, Train acc.: 91.41%\n",
      "Step [300/469], Loss: 0.2230, Train acc.: 94.53%\n",
      "Step [400/469], Loss: 0.2488, Train acc.: 93.75%\n",
      "Step [469/469], Loss: 0.3169, Train acc.: 90.62%\n",
      "Epoch 3 / 10\n",
      "Step [100/469], Loss: 0.2746, Train acc.: 91.41%\n",
      "Step [200/469], Loss: 0.2869, Train acc.: 92.97%\n",
      "Step [300/469], Loss: 0.2357, Train acc.: 91.41%\n",
      "Step [400/469], Loss: 0.4042, Train acc.: 92.19%\n",
      "Step [469/469], Loss: 0.2033, Train acc.: 94.79%\n",
      "Epoch 4 / 10\n",
      "Step [100/469], Loss: 0.2446, Train acc.: 93.75%\n",
      "Step [200/469], Loss: 0.2469, Train acc.: 89.06%\n",
      "Step [300/469], Loss: 0.3155, Train acc.: 90.62%\n",
      "Step [400/469], Loss: 0.3016, Train acc.: 92.19%\n",
      "Step [469/469], Loss: 0.3372, Train acc.: 90.62%\n",
      "Epoch 5 / 10\n",
      "Step [100/469], Loss: 0.2668, Train acc.: 92.97%\n",
      "Step [200/469], Loss: 0.3201, Train acc.: 89.06%\n",
      "Step [300/469], Loss: 0.3214, Train acc.: 91.41%\n",
      "Step [400/469], Loss: 0.2309, Train acc.: 93.75%\n",
      "Step [469/469], Loss: 0.3781, Train acc.: 87.50%\n",
      "Epoch 6 / 10\n",
      "Step [100/469], Loss: 0.2252, Train acc.: 93.75%\n",
      "Step [200/469], Loss: 0.4067, Train acc.: 91.41%\n",
      "Step [300/469], Loss: 0.3277, Train acc.: 92.97%\n",
      "Step [400/469], Loss: 0.2759, Train acc.: 93.75%\n",
      "Step [469/469], Loss: 0.2063, Train acc.: 93.75%\n",
      "Epoch 7 / 10\n",
      "Step [100/469], Loss: 0.2949, Train acc.: 92.97%\n",
      "Step [200/469], Loss: 0.2471, Train acc.: 92.19%\n",
      "Step [300/469], Loss: 0.2714, Train acc.: 92.97%\n",
      "Step [400/469], Loss: 0.2142, Train acc.: 96.09%\n",
      "Step [469/469], Loss: 0.1667, Train acc.: 94.79%\n",
      "Epoch 8 / 10\n",
      "Step [100/469], Loss: 0.3208, Train acc.: 92.97%\n",
      "Step [200/469], Loss: 0.1574, Train acc.: 95.31%\n",
      "Step [300/469], Loss: 0.2276, Train acc.: 92.97%\n",
      "Step [400/469], Loss: 0.3082, Train acc.: 89.84%\n",
      "Step [469/469], Loss: 0.0951, Train acc.: 97.92%\n",
      "Epoch 9 / 10\n",
      "Step [100/469], Loss: 0.2642, Train acc.: 93.75%\n",
      "Step [200/469], Loss: 0.2360, Train acc.: 96.09%\n",
      "Step [300/469], Loss: 0.1779, Train acc.: 93.75%\n",
      "Step [400/469], Loss: 0.2480, Train acc.: 93.75%\n",
      "Step [469/469], Loss: 0.3003, Train acc.: 89.58%\n",
      "Epoch 10 / 10\n",
      "Step [100/469], Loss: 0.3360, Train acc.: 89.06%\n"
     ]
    }
   ],
   "source": [
    "slp = SLP(28*28, 10)\n",
    "model = NN_classifier(slp, 10)\n",
    "model.prepare_data(datasets.MNIST)\n",
    "model.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_mnist_image(X, title=\"\", ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt\n",
    "    ax.imshow(X.reshape(28,28), cmap = plt.cm.gray, interpolation='nearest', clim=(0, 255))\n",
    "    ax.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat tensor([[9.4448e-04, 1.3246e-04, 4.3790e-04, 6.0623e-01, 6.6599e-04, 3.7756e-01,\n",
      "         4.2055e-04, 2.6606e-05, 1.3158e-02, 4.1890e-04]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26568/2673371724.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"y_hat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mxp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madv_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0myp_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0myp_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26568/628737333.py\u001b[0m in \u001b[0;36madv_example\u001b[1;34m(self, x, y, eps)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# Compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "for X, Y in model.train_loader:\n",
    "    x = X[0]\n",
    "    y = Y[0]\n",
    "    y_hat = model.predict_proba(x)\n",
    "    print (\"y_hat\", y_hat)\n",
    "    xp = model.adv_example(x, y, 0.1)\n",
    "    yp_hat = model.predict_proba(xp)\n",
    "    print (yp_hat)\n",
    "    plot_mnist_image(x, \"original\")\n",
    "    plot_mnist_image(xp, \"adv. example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26568/3321720506.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict_proba(x)\n",
    "print (y_hat)\n",
    "xp = model.adv_example(x, y, 0.1)\n",
    "yp_hat = model.predict_proba(xp)\n",
    "print (yp_hat)\n",
    "plot_mnist_image(x, \"original\")\n",
    "plot_mnist_image(xp, \"adv. example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6-4-3.  Adding hidden layer\n",
    "- class TLP : Two layer perceptron\n",
    "    - input layer $\\to$ hidden layer $\\to$ output layer\n",
    "\n",
    "<img src=\"figures/Ch6.TLP.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(D_in, H)\n",
    "        self.fc2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        h = self.fc1(x)\n",
    "        h = F.relu(h)\n",
    "        y = self.fc2(h)\n",
    "        return y  # softmax is done within F.cross_entropy\n",
    "        # return F.softmax(y, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &nbsp;\n",
    "### __Non-linearity__ is essential\n",
    "* stacking 2 linear layers == single linear layer  \n",
    "<img src=\"figures/Ch6.Non-linearity.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlp = TLP(28*28, 256, 10)\n",
    "model = NN_classifier(tlp, 10)\n",
    "model.prepare_data(datasets.MNIST)\n",
    "model.fit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.MLP accuracy.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &nbsp;\n",
    "### 6-4-4. Multi-Layer Perceptron \n",
    "- class MLP\n",
    "- multiple hidden layers\n",
    "    - input layer $\\to$ hidden layer $\\to \\cdots \\to$ hidden layer $\\to$ output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.MLP.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, lsize):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.n_layers = len(lsize) - 1\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers.append(torch.nn.Linear(lsize[i], lsize[i+1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.layers[i](x)\n",
    "            if i < self.n_layers-1:\n",
    "                # x = torch.tanh(x)\n",
    "                # x = F.relu(x)\n",
    "                x = F.leaky_relu(x)\n",
    "                # x = F.elu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8752600fcfc04827a6d7db15e6733183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f5435e79cb4e67acd985ab9b55d9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7893cccb8252493dac7209cb9188461e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900f086fbd364e2ea6d7bad778b870af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Epoch 1 / 10\n",
      "Step [100/469], Loss: 0.3583, Train acc.: 87.50%\n",
      "Step [200/469], Loss: 0.2118, Train acc.: 92.19%\n",
      "Step [300/469], Loss: 0.1101, Train acc.: 94.53%\n",
      "Step [400/469], Loss: 0.1293, Train acc.: 96.09%\n",
      "Step [469/469], Loss: 0.0923, Train acc.: 95.83%\n",
      "Epoch 2 / 10\n",
      "Step [100/469], Loss: 0.0913, Train acc.: 96.88%\n",
      "Step [200/469], Loss: 0.1438, Train acc.: 95.31%\n",
      "Step [300/469], Loss: 0.0900, Train acc.: 96.88%\n",
      "Step [400/469], Loss: 0.0725, Train acc.: 97.66%\n",
      "Step [469/469], Loss: 0.0346, Train acc.: 98.96%\n",
      "Epoch 3 / 10\n",
      "Step [100/469], Loss: 0.1376, Train acc.: 96.09%\n",
      "Step [200/469], Loss: 0.0841, Train acc.: 97.66%\n",
      "Step [300/469], Loss: 0.0819, Train acc.: 96.88%\n",
      "Step [400/469], Loss: 0.0839, Train acc.: 96.88%\n",
      "Step [469/469], Loss: 0.0589, Train acc.: 97.92%\n",
      "Epoch 4 / 10\n",
      "Step [100/469], Loss: 0.0484, Train acc.: 98.44%\n",
      "Step [200/469], Loss: 0.0899, Train acc.: 97.66%\n",
      "Step [300/469], Loss: 0.1643, Train acc.: 95.31%\n",
      "Step [400/469], Loss: 0.1251, Train acc.: 96.09%\n",
      "Step [469/469], Loss: 0.0193, Train acc.: 100.00%\n",
      "Epoch 5 / 10\n",
      "Step [100/469], Loss: 0.0827, Train acc.: 97.66%\n",
      "Step [200/469], Loss: 0.0407, Train acc.: 97.66%\n",
      "Step [300/469], Loss: 0.0404, Train acc.: 98.44%\n",
      "Step [400/469], Loss: 0.0666, Train acc.: 97.66%\n",
      "Step [469/469], Loss: 0.0649, Train acc.: 97.92%\n",
      "Epoch 6 / 10\n",
      "Step [100/469], Loss: 0.0415, Train acc.: 97.66%\n",
      "Step [200/469], Loss: 0.0339, Train acc.: 98.44%\n",
      "Step [300/469], Loss: 0.0288, Train acc.: 99.22%\n",
      "Step [400/469], Loss: 0.0713, Train acc.: 98.44%\n",
      "Step [469/469], Loss: 0.0487, Train acc.: 97.92%\n",
      "Epoch 7 / 10\n",
      "Step [100/469], Loss: 0.0454, Train acc.: 98.44%\n",
      "Step [200/469], Loss: 0.0401, Train acc.: 97.66%\n",
      "Step [300/469], Loss: 0.0206, Train acc.: 100.00%\n",
      "Step [400/469], Loss: 0.0517, Train acc.: 98.44%\n",
      "Step [469/469], Loss: 0.0922, Train acc.: 96.88%\n",
      "Epoch 8 / 10\n",
      "Step [100/469], Loss: 0.0272, Train acc.: 98.44%\n",
      "Step [200/469], Loss: 0.0501, Train acc.: 99.22%\n",
      "Step [300/469], Loss: 0.0416, Train acc.: 99.22%\n",
      "Step [400/469], Loss: 0.0543, Train acc.: 96.88%\n",
      "Step [469/469], Loss: 0.0435, Train acc.: 96.88%\n",
      "Epoch 9 / 10\n",
      "Step [100/469], Loss: 0.0424, Train acc.: 97.66%\n",
      "Step [200/469], Loss: 0.0557, Train acc.: 98.44%\n",
      "Step [300/469], Loss: 0.0726, Train acc.: 96.09%\n",
      "Step [400/469], Loss: 0.0507, Train acc.: 99.22%\n",
      "Step [469/469], Loss: 0.0233, Train acc.: 98.96%\n",
      "Epoch 10 / 10\n",
      "Step [100/469], Loss: 0.1192, Train acc.: 96.09%\n",
      "Step [200/469], Loss: 0.0570, Train acc.: 97.66%\n",
      "Step [300/469], Loss: 0.1292, Train acc.: 96.88%\n",
      "Step [400/469], Loss: 0.0330, Train acc.: 100.00%\n",
      "Step [469/469], Loss: 0.0221, Train acc.: 100.00%\n",
      "Test accuracy of the model: 97.93%\n",
      "[[ 968    1    1    0    1    0    6    1    0    2]\n",
      " [   0 1127    3    0    0    0    2    0    3    0]\n",
      " [   6    0 1014    1    2    0    2    3    2    2]\n",
      " [   1    0    4  989    0    6    0    2    4    4]\n",
      " [   1    0    1    0  969    0    8    1    1    1]\n",
      " [   3    1    0    7    1  864   11    1    4    0]\n",
      " [   2    1    0    0    2    1  952    0    0    0]\n",
      " [   1    7   15    2    1    0    1  987    2   12]\n",
      " [   7    0    4    1    1    3   10    2  942    4]\n",
      " [   2    2    0    4   10    7    2    0    1  981]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp = MLP([28*28, 256, 256, 256, 10])\n",
    "model = NN_classifier(mlp, 10)\n",
    "model.prepare_data(datasets.MNIST)\n",
    "model.fit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &nbsp;\n",
    "## 6-5. Convolution\n",
    "### 6-5-1. convolution operation\n",
    "* $y(i,j) = \\sum_{(k,l)\\in \\{-d,...,+d\\}} f(k,l) x(i+k,j+l)$\n",
    "    * $x(i,j)$ : source (input) pixel\n",
    "    * $y(i,j)$ : destination (output) pixel\n",
    "    * $f(k,l)$ : colvolution filter pixel\n",
    "        * $(2d+1)\\times(2d+1)$ : filter size\n",
    "        * $k, l \\in \\{-d, ..., +d\\}$\n",
    "\n",
    "### 6-5-2. Convolution is quite a successful technique in image processing\n",
    "- heavily depends on the choice of convolution filters\n",
    "    * which filters to use?\n",
    "        * vertical/horizontal edge detector\n",
    "        * circle detector, corner detector, ...\n",
    "    * feature engineering on the result of convolution : not generic\n",
    "        * hand-crafted task-specific features : time consuming\n",
    "            * features for cat classfier : pointed ear, eye distance, nose, ...\n",
    "    * a general approach : a model that can __learn features from data__\n",
    "        * __representation learning__: learn good feature representation\n",
    "        * usually deep NN is used $\\to$ __deep learning__\n",
    "\n",
    "<img src=\"figures/Ch6.Convolution.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5-3. Max-Pooling\n",
    "- to reduce image size $\\Rightarrow$ condensed information\n",
    "- sub-sampling (down-sampling) by taking maximum \n",
    "\n",
    "<img src=\"figures/Ch6.Max-pooling.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5-4. CNN : Convolutional Neural Network architecture\n",
    "<img src=\"figures/Ch6.CNN.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.CNN accuracy.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, i_size, i_channels, D_out):\n",
    "        super().__init__()\n",
    "        o1_channels = 4*i_channels\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(i_channels, o1_channels, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(o1_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        o1_size = i_size // 2  # padding=2 -> no size reduction\n",
    "        o2_channels = 4*o1_channels\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(o1_channels, o2_channels, kernel_size=5, padding=0),\n",
    "            nn.BatchNorm2d(o2_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        o2_size = (o1_size - 4) // 2  # padding=0\n",
    "        G = o2_size*o2_size*o2_channels\n",
    "        self.block3 = nn.Sequential(nn.Linear(G, G*2), nn.ReLU(), nn.Linear(G*2, D_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.block3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x0000027E2C664310>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\tqdm\\std.py\", line 1152, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\tqdm\\notebook.py\", line 283, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18480/1643294283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNN_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18480/3431160735.py\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(self, data_class, batch_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Downloading {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                     download_and_extract_archive(\n\u001b[0m\u001b[0;32m    177\u001b[0m                         \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0marchive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloading '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0m_urlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'https'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[1;34m(url, filename, chunk_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# Prepare IPython progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# #187 #451 #558 #872\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             raise ImportError(\n\u001b[0m\u001b[0;32m    113\u001b[0m                 \u001b[1;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[1;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "cnn = CNN(28, 1, 10)\n",
    "model = NN_classifier(cnn, 10)\n",
    "model.prepare_data(datasets.MNIST)\n",
    "model.fit(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5-4. CNN for Classifying CIFAR-10 data\n",
    "- Collection of tiny images with labels\n",
    "    * image size : 32x32, color(rgb 3 channels)\n",
    "    * 60,000 images : 50,000 for training, 10,000 for test\n",
    "        * collected and labeled by Alex Krizhevsky, V. Nair, and Geoffrey Hinton\n",
    "    * 10 class labels : airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "        * 6,000 images per class\n",
    "- cf. CIFAR-100 : 100 classes, 600 images per class\n",
    "- CIFAR stands for Canadia Institute for Advanced Research\n",
    "\n",
    "<img src=\"figures/Ch6.CIFAR-10.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.CIFAR-10 accuracy.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(32, 3, 10)\n",
    "model = NN_classifier(cnn, 10)\n",
    "model.prepare_optimizer(lr=0.01, wd=0.001)\n",
    "model.prepare_data(datasets.CIFAR10, batch_size=12500)\n",
    "model.fit(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prepare_optimizer(lr=0.0001, wd=0.001)\n",
    "model.fit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __6-6. Deep Learning__?\n",
    "\n",
    "<img src=\"figures/Ch6.Deep learning.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Ch6.Why DNN.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"figures/Ch6.ImageNet.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"figures/Ch6.ImageNet Winners.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## __6-7. Regression__ with NN\n",
    "- __Parametric__ regression\n",
    "    * assumes parametric form of function family\n",
    "    * find parameters by optimization\n",
    "    - simple linear regression\n",
    "        * $ y_i = w_0 + w_1x_i + \\epsilon_i = \\textbf{x}_i^T \\textbf{w} + \\epsilon_i $ \n",
    "            * $ \\textbf{x}_i = (1, x_i)^T $ : features\n",
    "            * $ \\textbf{w} = (w_0, w_1)^T $ : parameters\n",
    "    - regression with polynomial of degree p : in parameter vector $ \\textbf{w} $ \n",
    "        * $ y_i = w_0 + w_1x_i + w_2x_i^2 + ... + w_px_i^p + \\epsilon_i = \\textbf{x}_i^T \\textbf{w} + \\epsilon_i $ \n",
    "            * $ \\textbf{x}_i = (1, x_i, x_i^2,..., x_i^p)^T $ : polynomial features\n",
    "            * $ \\textbf{w} = (w_0, w_1, w_2, ..., w_p)^T $ : parameters\n",
    "    - regression with special non-linear functions\n",
    "        * $ y_i = w_0 + \\log(x_i-w_1) + \\sin(w_2x_i + w_3) + \\epsilon_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Non-parametric__ regression \n",
    "    * does not assume parametric functional form\n",
    "    * examples\n",
    "        * neural net\n",
    "        * decision tree\n",
    "        * Gaussian process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# &nbsp;\n",
    "### 6-7-1. Sample data for regression\n",
    "<img src=\"figures/Ch6.Regression w NN.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-7-2. class NN_regressor\n",
    "- inherits NN_classifier\n",
    "    * many methods are common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5  \n",
    "class NN_regressor(NN_classifier):\n",
    "    def __init__(self, nn_model):\n",
    "        super().__init__(nn_model, 1)\n",
    "        self.prepare_optimizer(lr=0.001, wd=0.0001)\n",
    "\n",
    "    def prepare_N_data(self, n, sigma=0.02):\n",
    "        X = np.random.rand(n)*4\n",
    "        Y = 0.5*X + 0.5\n",
    "        for i in range(n):\n",
    "            x = X[i]\n",
    "            if x > 1:\n",
    "                if x < 2:\n",
    "                    Y[i] = 0.5*(x-2)**2 + 0.5\n",
    "                else:\n",
    "                    Y[i] = np.log(x - 1) + 0.5\n",
    "        Y += np.random.randn(n)*sigma\n",
    "\n",
    "        Xt = torch.tensor(X, dtype=torch.float32).view((n,1)).to(self.device)\n",
    "        Yt = torch.tensor(Y, dtype=torch.float32).view((n,1)).to(self.device)\n",
    "        return Xt, Yt, X, Y        \n",
    "        \n",
    "    def prepare_data(self, batch_size=256):\n",
    "        self.X_trn, self.Y_trn, self.Xnp_trn, self.Ynp_trn = self.prepare_N_data(5000)\n",
    "        self.X_tst, self.Y_tst, self.Xnp_tst, self.Ynp_tst = self.prepare_N_data(1000)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    \n",
    "    def fit_epoch(self):\n",
    "        self.nn_model.train()\n",
    "        N = self.X_trn.shape[0]\n",
    "        m = self.batch_size\n",
    "        n_batch = N // m\n",
    "        es_score = 0\n",
    "        for i in range(n_batch):\n",
    "            idx = np.random.choice(N, m, replace=False)\n",
    "            mb_X = self.X_trn[idx,0].view((m,1))\n",
    "            mb_Y = self.Y_trn[idx,0].view((m,1))\n",
    "            \n",
    "            # Forward pass\n",
    "            Y_hat = self.nn_model(mb_X)\n",
    "            \n",
    "            # Compute loss            \n",
    "            loss = F.mse_loss(mb_Y, Y_hat)\n",
    "\n",
    "            # Backprop\n",
    "            self.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "\n",
    "            # Track MSE\n",
    "            score = loss.item()\n",
    "            self.score_list.append(score)\n",
    "        \n",
    "        \n",
    "    def fit(self, n_epochs=50, plot=True):\n",
    "        loss_list = []\n",
    "        self.score_list = []\n",
    "        plt.ion()\n",
    "        for i in range(n_epochs):\n",
    "            self.fit_epoch()\n",
    "            self.test(f'Training epoch {i} ')\n",
    "            if plot:\n",
    "                self.plot_data()\n",
    "\n",
    "        plt.ioff()\n",
    "        # plt.plot(self.score_list)\n",
    "\n",
    "\n",
    "    def plot_data(self):\n",
    "        self.nn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            Yhat_tst = self.nn_model(self.X_tst).cpu().numpy()\n",
    "\n",
    "        plt.gcf().clear()\n",
    "        plt.plot(self.Xnp_trn, self.Ynp_trn, 'b.')\n",
    "        plt.plot(self.Xnp_tst, Yhat_tst, 'r.')\n",
    "        plt.draw()\n",
    "        plt.pause(0.01)        \n",
    "\n",
    "        \n",
    "    def test(self, prefix=''):\n",
    "        self.nn_model.eval()\n",
    "        r2 = self.score(self.X_tst, self.Y_tst)\n",
    "        print(f'{prefix}Test R2 score of the model : {r2:.4f}')\n",
    "\n",
    "        \n",
    "    def score(self, X, Y):\n",
    "        self.nn_model.eval()\n",
    "        X = X.to(self.device)\n",
    "        Y = Y.to(self.device)\n",
    "        Y_hat = self.nn_model(X)\n",
    "        mse = F.mse_loss(Y, Y_hat)\n",
    "        var = Y.var()\n",
    "        r2 = 1 - mse/var\n",
    "        return r2.detach().item()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.to(self.device)\n",
    "        return self.nn_model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-7-3. Regression with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 64\n",
    "mlp = MLP([1,H,H,H,H,1])\n",
    "model = NN_regressor(mlp)\n",
    "model.prepare_data()\n",
    "model.fit(n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6-7-4. Effects of hidden layer width and depth\n",
    "* NN is a univeral approximator\n",
    "    * NN can approximate any complex decision function within specified tolerance\n",
    "    * _universal approximation theorem_\n",
    "<img src=\"figures/Ch6.NN width & depth.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 8\n",
    "mlp = MLP([1,H,H,H,H,H,H,H,H,H,H,1])\n",
    "model = NN_regressor(mlp)\n",
    "model.prepare_data()\n",
    "model.fit(n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# &nbsp;\n",
    "## 6-8. Optimization for NN learning\n",
    "### Gradient descent (__GD__)\n",
    "* $\\mathbf{w}_{t+1} \\gets \\mathbf{w}_t - \\alpha_t \\nabla_\\mathbf{w}L$\n",
    "* $\\alpha_t$ : learning rate, step size\n",
    "    * how to set $\\alpha_t$ : non-trivial\n",
    "        * easily diverges with large $\\alpha_t$  \n",
    "        * with small enough $\\alpha_t$, GD coverges to a local optimum\n",
    "            * too small $\\alpha_t \\to $ too slow covergence\n",
    "        * line search\n",
    "            * Back-tracking line search method (Amijo rule)\n",
    "        * 2nd order method (Newton method) : use Hessian $\\nabla_\\mathbf{w}^2L$\n",
    "            * BFGS method, L-BFGS method  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stochastic gradient descent (__SGD__)\n",
    "* using a subset of data (mini-batch) to estimate gradient\n",
    "    * full gradient (gradient with full data) can take too much computation\n",
    "    * updating $\\mathbf{w}_t$ with sample estimates $\\hat{\\nabla}_\\mathbf{w}L$ instead of true gradient $\\nabla_\\mathbf{w}L$\n",
    "        * will it converge?\n",
    "        * yes, under Robbins-Monro Conditions on Stochastic Approximation\n",
    "            * $\\sum_{t=1}^{\\infty}\\alpha_t^2 < \\infty$ ( $\\Rightarrow$  decreasing to 0 )\n",
    "            * $\\sum_{t=1}^{\\infty}\\alpha_t = \\infty$ ( $\\Rightarrow$  not too fast )\n",
    "            * R-M conds are satified if $\\alpha_t = \\frac{1}{t^p}$ where $0.5 < p \\leq 1$         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adaptive methods\n",
    "- Momentum\n",
    "    * $\\mathbf{v} \\gets \\mu\\mathbf{v} - \\alpha_t \\nabla_\\mathbf{w}L$\n",
    "    * $\\mathbf{w}_{t+1} \\gets \\mathbf{w}_t +\\mathbf{v}$\n",
    "- Nesterov Momentum\n",
    "- Adaptive methods\n",
    "    - AdaGrad, AdaDelta\n",
    "    - RProp, RMSProp\n",
    "    - Adam (Kingma & Ba, 2015) : very popular\n",
    "    \n",
    "#### Refer to \"Optimization for ML.pdf\" for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers in PyTorch\n",
    "* torch.optim.SGD(params, lr, momentum, weight_decay)\n",
    "    * params : parameters $\\mathbf{w}$ to optimize\n",
    "    * lr : (initial) learning rate $\\alpha$\n",
    "    * momentum : $\\mu$ (for $\\mathbf{v} \\gets \\mu\\mathbf{v} - \\alpha_t \\nabla_\\mathbf{w}L$)\n",
    "        * default momentum = 0, it is recommended to use momentun=0.9\n",
    "    * weight_decay : $\\lambda$ in L2 regularization \n",
    "        * $\\min L(\\mathbf{w}) + \\lambda|\\mathbf{w}|^2$\n",
    "        * default weight_decay = 0\n",
    "* torch.optim.Adam(parameters, lr, weight_decay) \n",
    "    * very popular adaptive method\n",
    "* torch.optim.LBFGS(parameters, lr, weight_decay)\n",
    "    * 2nd order method\n",
    "    * unstable when used with stochastic gradient (gradient from mini-batch of training data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_rehYX145nEk",
    "g4-XjayC8KO7"
   ],
   "name": "Lesson5-Python For Data Science-Python-Data-structure.ipynb의 사본",
   "provenance": [
    {
     "file_id": "https://github.com/paiml/python_for_datascience/blob/master/Lesson5_Python_For_Data_Science_Python_Data_structure.ipynb",
     "timestamp": 1629953121902
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
